{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "\n",
    "Q1. What is a parameter?  \n",
    "- **A parameter** is a variable used in a model to represent a certain characteristic or feature of the data. For example, in a linear regression model, the slope and intercept are parameters. Parameters are learned from the training data and are used to make predictions on new data.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q2. What is correlation?  \n",
    "- **Correlation** is a statistical measure that describes the extent to which two variables change together. It ranges from `-1 to 1` , where `1 indicates a perfect positive correlation` , `-1 indicates a perfect negative correlation` , and `0 indicates no correlation` . \n",
    "- **For example** , height and weight are often correlated because taller people tend to weigh more.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q3. What does negative correlation mean?  \n",
    "- **Negative correlation** means that as one variable increases, the other variable decreases. For example, the number of hours spent watching TV and grades in school might have a negative correlation, meaning that as TV watching increases, grades tend to decrease.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q4. Define Machine Learning. What are the main components in Machine Learning?  \n",
    "- **Machine Learning** is a field of artificial intelligence that uses statistical techniques to give computer systems the ability to learn from data and make decisions or predictions. \n",
    "- **The main components are:**\n",
    "  1. **Data:** The raw information used to train the model.\n",
    "  2. **Model:** The mathematical representation of the data.\n",
    "  3. **Algorithm:** The method used to train the model.\n",
    "  4. **Evaluation:** The process of assessing the model's performance.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q5. How does loss value help in determining whether the model is good or not?  \n",
    "- The loss value measures how well the model's predictions match the actual data. It quantifies the difference between the predicted values and the actual values. A lower loss value indicates a better fit of the model to the data, meaning the model's predictions are closer to the actual values. Common loss functions include Mean Squared Error (MSE) and Cross-Entropy Loss.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q6. What are continuous and categorical variables?  \n",
    "- **Continuous variables** can take any value within a range and are often measured. \n",
    "- **Examples include** height, weight, and temperature. \n",
    "- **Categorical variables** represent discrete categories or groups and are often counted. \n",
    "- **Examples include** gender, color, and type of vehicle.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q7. How do we handle categorical variables in Machine Learning? What are the common techniques?  \n",
    "- Handling categorical variables involves converting them into a numerical format that can be used by machine learning algorithms. \n",
    "- **Common techniques include:**\n",
    "  1. **One-Hot Encoding:** Converts each category into a binary vector.\n",
    "  2. **Label Encoding:** Assigns a unique integer to each category.\n",
    "  3. **Binary Encoding:** Combines label encoding and one-hot encoding.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q8. What do you mean by training and testing a dataset?  \n",
    "- **Training a dataset** involves using it to fit a model, meaning the model learns from the data. \n",
    "- **Testing a dataset** involves using it to evaluate the model's performance, meaning the model makes predictions on new, unseen data to assess how well it generalizes.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q9. What is sklearn.preprocessing?  \n",
    "- **sklearn.preprocessing** is a module in scikit-learn that provides functions and classes to preprocess data before training a model. It includes techniques for scaling, encoding, and normalizing data, which are essential steps to ensure that the data is in the right format for machine learning algorithms.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q10. What is a Test set?  \n",
    "- **A test set** is a subset of the dataset used to evaluate the performance of a trained model. It is not used during the training process, ensuring that the evaluation is unbiased and reflects the model's ability to generalize to new data.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q11. How do we split data for model fitting (training and testing) in Python?  \n",
    "- We can use the `train_test_split` function from scikit-learn to split data into training and testing sets. This function randomly divides the data, ensuring that both sets are representative of the overall dataset.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q12. How do you approach a Machine Learning problem?  \n",
    "- **The approach includes the following steps:**\n",
    "  **1. Understanding the problem:** Define the problem and the goal.\n",
    "  **2. Collecting data:** Gather relevant data from various sources.\n",
    "  **3. Preprocessing data:** Clean and prepare the data for analysis.\n",
    "  **4. Selecting a model:** Choose an appropriate machine learning model.\n",
    "  **5. Training the model:** Use the training data to fit the model.\n",
    "  **6. Evaluating the model:** Assess the model's performance using the test data.\n",
    "  **7. Tuning the model:** Optimize the model's parameters to improve performance.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q13. Why do we have to perform EDA before fitting a model to the data?  \n",
    "- **Exploratory Data Analysis (EDA)** helps in understanding the data, identifying patterns, detecting anomalies, and selecting appropriate features for the model. It involves visualizing the data, summarizing its main characteristics, and uncovering underlying structures, which are crucial steps before model fitting.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q14. What is correlation?  \n",
    "- **Correlation** is a statistical measure that describes the extent to which two variables change together. It ranges from -1 to 1, where 1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no correlation. For example, height and weight are often correlated because taller people tend to weigh more.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q15. What does negative correlation mean?  \n",
    "- Negative correlation means that as one variable increases, the other variable decreases. For example, the number of hours spent watching TV and grades in school might have a negative correlation, meaning that as TV watching increases, grades tend to decrease.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q16. How can you find correlation between variables in Python?  \n",
    "- We can use the `corr` method from pandas to find the correlation between variables. This method calculates the correlation coefficient for each pair of variables in the DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "data = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "correlation = data.corr()\n",
    "print(correlation)\n",
    "```\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q17. What is causation? Explain the difference between correlation and causation with an example.  \n",
    "- **Causation** indicates that one event is the result of the occurrence of the other event. **Correlation** does not imply causation. \n",
    "- **For example:** ice cream sales and drowning incidents are correlated because both increase during the summer, but buying ice cream does not cause drowning incidents.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q18. What is an Optimizer? What are different types of optimizers? Explain each with an example.  \n",
    "- An optimizer is an algorithm that adjusts the weights of a model to minimize the loss function. Different types of optimizers include:\n",
    "  **1. Gradient Descent:** Updates weights by moving in the direction of the negative gradient of the loss function.\n",
    "  **2. Adam:** Combines the advantages of two other extensions of stochastic gradient descent, namely AdaGrad and RMSProp.\n",
    "  **3. RMSprop:** Divides the learning rate by an exponentially decaying average of squared gradients.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "```\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q19. What is sklearn.linear_model?  \n",
    "- **sklearn.linear_model** is a module in scikit-learn that provides linear models such as Linear Regression, Ridge, and Lasso. These models are used for predicting a target variable based on one or more predictor variables.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q20. What does model.fit() do? What arguments must be given?  \n",
    "- model.fit() trains the model on the given data. It requires the training data (features) and the target values as arguments. This method adjusts the model parameters to minimize the loss function.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q21. What does model.predict() do? What arguments must be given?  \n",
    "- **model.predict()** makes predictions using the trained model. It requires the input data (features) as an argument. This method returns the predicted values for the input data.\n",
    "\n",
    "```python\n",
    "predictions = model.predict(X_test)\n",
    "```\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q22. What are continuous and categorical variables?  \n",
    "- **Continuous variables** can take any value within a range and are often measured. \n",
    "- **Examples include** height, weight, and temperature. \n",
    "- **Categorical variables** represent discrete categories or groups and are often counted. \n",
    "- **Examples include** gender, color, and type of vehicle.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q23. What is feature scaling? How does it help in Machine Learning?  \n",
    "- Feature scaling is the process of normalizing the range of features in the data. It helps in improving the performance and training stability of the model by ensuring that all features contribute equally to the result. Common techniques include standardization (z-score normalization) and normalization (min-max scaling).\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q24. How do we perform scaling in Python?  \n",
    "- We can use the `StandardScaler` from scikit-learn to perform scaling. This scaler standardizes features by removing the mean and scaling to unit variance.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q25. What is sklearn.preprocessing?  \n",
    "- **sklearn.preprocessing** is a module in scikit-learn that provides functions and classes to preprocess data before training a model. It includes techniques for scaling, encoding, and normalizing data, which are essential steps to ensure that the data is in the right format for machine learning algorithms.\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q26. How do we split data for model fitting (training and testing) in Python?  \n",
    "- We can use the `train_test_split` function from scikit-learn to split data into training and testing sets. This function randomly divides the data, ensuring that both sets are representative of the overall dataset.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "Q27. Explain data encoding?  \n",
    "- **Data encoding** is the process of converting categorical data into numerical format. Common techniques include one-hot encoding, which creates binary columns for each category, and label encoding, which assigns a unique integer to each category. These techniques allow machine learning algorithms to process categorical data.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(categorical_data)\n",
    "```\n",
    "\n",
    "-----------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
